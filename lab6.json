{"paragraphs":[{"text":"%pyspark\ndatadir = \"/home/spark/Documents/spark-workshop/data\"","dateUpdated":"Jun 22, 2016 9:12:47 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1466618830027_-1380837085","id":"20160622-210710_1546113137","dateCreated":"Jun 22, 2016 9:07:10 PM","dateStarted":"Jun 22, 2016 9:09:38 PM","status":"ABORT","progressUpdateIntervalMs":500,"$$hashKey":"object:1065"},{"text":"%md\nIn this lab, you will run the [PageRank](https://en.wikipedia.org/wiki/PageRank) algorithm on a dataset of movie references, and try to identify the most popular movies based on how many references they have. The dataset you'll be working with is [provided by IMDB](http://www.imdb.com/interfaces).","dateUpdated":"Jun 22, 2016 9:12:41 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1466618859625_-1559699351","id":"20160622-210739_879582469","result":{"code":"SUCCESS","type":"HTML","msg":"<p>In this lab, you will run the <a href=\"https://en.wikipedia.org/wiki/PageRank\">PageRank</a> algorithm on a dataset of movie references, and try to identify the most popular movies based on how many references they have. The dataset you'll be working with is <a href=\"http://www.imdb.com/interfaces\">provided by IMDB</a>.</p>\n"},"dateCreated":"Jun 22, 2016 9:07:39 PM","dateStarted":"Jun 22, 2016 9:07:43 PM","dateFinished":"Jun 22, 2016 9:07:46 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1066"},{"text":"%md\n#### Task 1: Inspecting the Data\n\nThe original IMDB dataset is not very friendly for automatic processing. You can find it in the `~/data` folder of the VirtualBox appliance, or download it yourself from the IMDB FTP website -- it's the `movie-links.list` dataset. Here's a sampler:\n\n```\n\"#1 Single\" (2006)\n  (referenced in \"Howard Stern on Demand\" (2005) {Lisa Loeb & Sister})\n\n\"#LawstinWoods\" (2013) {The Arrival (#1.1)}\n  (references \"Lost\" (2004))\n  (references Kenny Rogers and Dolly Parton: Together (1985) (TV))\n  (references The Grudge (2004))\n  (references The Ring (2002))\n```\n\nInstead of using this raw dataset, there's a pre-processed one available in the `processed-movie-links.txt` file (it doesn't contain all the information from the first one, but we can live with that). Again, here's a sample:\n\n```\n$ head processed-movie-links.txt\n#LawstinWoods --> Lost\n#LawstinWoods --> Kenny Rogers and Dolly Parton: Together\n#LawstinWoods --> The Grudge\n#LawstinWoods --> The Ring\n#MonologueWars --> Trainspotting\nCommunity --> $#*! My Dad Says\nConan --> $#*! My Dad Says\nGeeks Who Drink --> $#*! My Dad Says\nLate Show with David Letterman --> $#*! My Dad Says\n```\n","dateUpdated":"Jun 22, 2016 9:12:41 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1466618863563_-1201882874","id":"20160622-210743_1542395530","result":{"code":"SUCCESS","type":"HTML","msg":"<h4>Task 1: Inspecting the Data</h4>\n<p>The original IMDB dataset is not very friendly for automatic processing. You can find it in the <code>~/data</code> folder of the VirtualBox appliance, or download it yourself from the IMDB FTP website &ndash; it's the <code>movie-links.list</code> dataset. Here's a sampler:</p>\n<pre><code>\"#1 Single\" (2006)\n  (referenced in \"Howard Stern on Demand\" (2005) {Lisa Loeb &amp; Sister})\n\n\"#LawstinWoods\" (2013) {The Arrival (#1.1)}\n  (references \"Lost\" (2004))\n  (references Kenny Rogers and Dolly Parton: Together (1985) (TV))\n  (references The Grudge (2004))\n  (references The Ring (2002))\n</code></pre>\n<p>Instead of using this raw dataset, there's a pre-processed one available in the <code>processed-movie-links.txt</code> file (it doesn't contain all the information from the first one, but we can live with that). Again, here's a sample:</p>\n<pre><code>$ head processed-movie-links.txt\n#LawstinWoods --&gt; Lost\n#LawstinWoods --&gt; Kenny Rogers and Dolly Parton: Together\n#LawstinWoods --&gt; The Grudge\n#LawstinWoods --&gt; The Ring\n#MonologueWars --&gt; Trainspotting\nCommunity --&gt; $#*! My Dad Says\nConan --&gt; $#*! My Dad Says\nGeeks Who Drink --&gt; $#*! My Dad Says\nLate Show with David Letterman --&gt; $#*! My Dad Says\n</code></pre>\n"},"dateCreated":"Jun 22, 2016 9:07:43 PM","dateStarted":"Jun 22, 2016 9:09:51 PM","dateFinished":"Jun 22, 2016 9:09:53 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1067"},{"text":"%md\n#### Task 2: Finding Top Movies\n\nNow it's time to implement the PageRank algorithm. It's probably the most challenging task so far, so here are some instructions that might help.\n\n> **NOTE**: This is a very naive implementation of PageRank, which doesn't really try to optimize and minimize data shuffling. The GraphX library, which is also part of Spark, has a [native implementation of PageRank](https://spark.apache.org/docs/1.1.0/graphx-programming-guide.html#pagerank). You can try it in Task 3.\n\nBegin by parsing the movie references to an RDD called `links` (using `SparkContext.textFile` and `map`) and processing it into key/value pairs where the key is the movie and the value is a list of all movies referenced by it.\n\nNext, create an RDD called `ranks` of key/value pairs where the key is the movie and the value is its rank, set to 1.0 initially for all movies.\n\nNext, write a function `computeContribs` that takes a list of referenced movies and the referencing movie's rank, and returns a list of key/value pairs where the key is the movie and the value is its rank contribution. Each of the referenced movies gets an equal portion of the referencing movie's rank. For example, if \"Star Wars\" currently has rank 1.0 and references \"Wizard of Oz\" and \"Star Trek\", then the function should return two pairs: `(\"Wizard of Oz\", 0.5)` and `(\"Star Trek\", 0.5)`.\n\nNext, we're getting to the heart of the algorithm. In a loop that repeats 10 times, compute a new RDD called `contribs` which is formed by joining `links` and `ranks` (the join is on the movie name). Use `flatMap` to collect the results from `computeContribs` on each key/value pair in the result of the join. To understand what we're doing, consider that joining `links` and `ranks` produces a pair RDD whose elements look like this:\n\n```python\n(\"Star Wars\", (\"Wizard of Oz\", \"Star Trek\", 0.8))\n```\n\nNow, invoking `computeContribs` on the value of this pair produces a list of pairs:\n\n```python\n[(\"Wizard of Oz\", 0.4), (\"Star Trek\", 0.4)]\n```\n\nBy applying `computeContribs` and collecting the results with `flatMap`, we get a pair RDD that has, for each movie, its contribution from each of its neighbors. You should now sum (reduce) this pair RDD by key, so we get the sum of each movie's contributions from its neighbors.\n\nNext, the PageRank algorithm dictates that we should recompute each movie's rank from the `ranks` RDD as 0.15 + 0.85 times its neighbors' contribution (you can use `mapValues` for this). This recomputation produces a new input value for `ranks`.","dateUpdated":"Jun 22, 2016 9:12:41 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1466618991207_1575016860","id":"20160622-210951_1514418424","result":{"code":"SUCCESS","type":"HTML","msg":"<h4>Task 2: Finding Top Movies</h4>\n<p>Now it's time to implement the PageRank algorithm. It's probably the most challenging task so far, so here are some instructions that might help.</p>\n<blockquote><p><strong>NOTE</strong>: This is a very naive implementation of PageRank, which doesn't really try to optimize and minimize data shuffling. The GraphX library, which is also part of Spark, has a <a href=\"https://spark.apache.org/docs/1.1.0/graphx-programming-guide.html#pagerank\">native implementation of PageRank</a>. You can try it in Task 3.</p>\n</blockquote>\n<p>Begin by parsing the movie references to an RDD called <code>links</code> (using <code>SparkContext.textFile</code> and <code>map</code>) and processing it into key/value pairs where the key is the movie and the value is a list of all movies referenced by it.</p>\n<p>Next, create an RDD called <code>ranks</code> of key/value pairs where the key is the movie and the value is its rank, set to 1.0 initially for all movies.</p>\n<p>Next, write a function <code>computeContribs</code> that takes a list of referenced movies and the referencing movie's rank, and returns a list of key/value pairs where the key is the movie and the value is its rank contribution. Each of the referenced movies gets an equal portion of the referencing movie's rank. For example, if &ldquo;Star Wars&rdquo; currently has rank 1.0 and references &ldquo;Wizard of Oz&rdquo; and &ldquo;Star Trek&rdquo;, then the function should return two pairs: <code>(\"Wizard of Oz\", 0.5)</code> and <code>(\"Star Trek\", 0.5)</code>.</p>\n<p>Next, we're getting to the heart of the algorithm. In a loop that repeats 10 times, compute a new RDD called <code>contribs</code> which is formed by joining <code>links</code> and <code>ranks</code> (the join is on the movie name). Use <code>flatMap</code> to collect the results from <code>computeContribs</code> on each key/value pair in the result of the join. To understand what we're doing, consider that joining <code>links</code> and <code>ranks</code> produces a pair RDD whose elements look like this:</p>\n<pre><code class=\"python\">(\"Star Wars\", (\"Wizard of Oz\", \"Star Trek\", 0.8))\n</code></pre>\n<p>Now, invoking <code>computeContribs</code> on the value of this pair produces a list of pairs:</p>\n<pre><code class=\"python\">[(\"Wizard of Oz\", 0.4), (\"Star Trek\", 0.4)]\n</code></pre>\n<p>By applying <code>computeContribs</code> and collecting the results with <code>flatMap</code>, we get a pair RDD that has, for each movie, its contribution from each of its neighbors. You should now sum (reduce) this pair RDD by key, so we get the sum of each movie's contributions from its neighbors.</p>\n<p>Next, the PageRank algorithm dictates that we should recompute each movie's rank from the <code>ranks</code> RDD as 0.15 + 0.85 times its neighbors' contribution (you can use <code>mapValues</code> for this). This recomputation produces a new input value for <code>ranks</code>.</p>\n"},"dateCreated":"Jun 22, 2016 9:09:51 PM","dateStarted":"Jun 22, 2016 9:10:20 PM","dateFinished":"Jun 22, 2016 9:10:20 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1068"},{"text":"%md\nFinally, when your loop is done, display the 10 highest-ranked movies and their PageRank.\n\n**Solution**:\n\n```python\n# links is RDD of (movie, [referenced movies])\nlinks = sc.textFile(\"file:///home/vagrant/data/processed-movie-links.txt\") \\\n          .map(lambda line: line.split(\"-->\"))                             \\\n          .map(lambda (a, b): (a.strip(), b.strip()))                      \\\n          .distinct()                                                      \\\n          .groupByKey()                                                    \\\n          .cache()\n\n# ranks is RDD of (movie, 1.0)\nranks = links.map(lambda (movie, _): (movie, 1.0))\n\n# each of our references gets a contribution of our rank divided by the\n# total number of our references\ndef computeContribs(referenced, rank):\n    count = len(referenced)\n    for movie in referenced:\n        yield (movie, rank / count)\n\nfor _ in range(0, 10):\n    # recompute each movie's contributions from its referencing movies\n    contribs = links.join(ranks).flatMap(lambda (_, (referenced, rank)):\n        computeContribs(referenced, rank)\n                                        )\n    # recompute the movie's ranks by accounting all its referencing\n    # movies' contributions\n    ranks = contribs.reduceByKey(lambda a, b: a + b)                       \\\n                    .mapValues(lambda rank: rank*0.85 + 0.15)\n\nfor movie, rank in ranks.sortBy(lambda (_, rank): -rank).take(10):\n    print('\"%s\" has rank %2.2f' % (movie, rank))\n```","dateUpdated":"Jun 22, 2016 9:12:41 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1466619020617_-921756671","id":"20160622-211020_1281201580","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Finally, when your loop is done, display the 10 highest-ranked movies and their PageRank.</p>\n<p><strong>Solution</strong>:</p>\n<pre><code class=\"python\"># links is RDD of (movie, [referenced movies])\nlinks = sc.textFile(\"file:///home/vagrant/data/processed-movie-links.txt\") \\\n          .map(lambda line: line.split(\"--&gt;\"))                             \\\n          .map(lambda (a, b): (a.strip(), b.strip()))                      \\\n          .distinct()                                                      \\\n          .groupByKey()                                                    \\\n          .cache()\n\n# ranks is RDD of (movie, 1.0)\nranks = links.map(lambda (movie, _): (movie, 1.0))\n\n# each of our references gets a contribution of our rank divided by the\n# total number of our references\ndef computeContribs(referenced, rank):\n    count = len(referenced)\n    for movie in referenced:\n        yield (movie, rank / count)\n\nfor _ in range(0, 10):\n    # recompute each movie's contributions from its referencing movies\n    contribs = links.join(ranks).flatMap(lambda (_, (referenced, rank)):\n        computeContribs(referenced, rank)\n                                        )\n    # recompute the movie's ranks by accounting all its referencing\n    # movies' contributions\n    ranks = contribs.reduceByKey(lambda a, b: a + b)                       \\\n                    .mapValues(lambda rank: rank*0.85 + 0.15)\n\nfor movie, rank in ranks.sortBy(lambda (_, rank): -rank).take(10):\n    print('\"%s\" has rank %2.2f' % (movie, rank))\n</code></pre>\n"},"dateCreated":"Jun 22, 2016 9:10:20 PM","dateStarted":"Jun 22, 2016 9:10:42 PM","dateFinished":"Jun 22, 2016 9:10:42 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1069"},{"text":"%md\n#### Task 3: GraphX PageRank\n\nThe PageRank algorithm we implemented in the previous task is not very efficient. For example, running it on our dataset for 100 iterations took approximately 15 minutes on a 4-core machine. Considering that there are \"just\" about 25,000 movies ranked, this is not a very good result.\n\nSpark ships with a native graph algorithm library called GraphX. Unfortunately, it doesn't yet have a Python binding -- you can only use it from Scala and Java. But we're not going to let that stop us!\n\nNavigate to the Spark installation directory (`~/spark` in the VirtualBox appliance) and run `bin/spark-shell`. This is the Spark Scala REPL, which is very similar to PySpark, except it uses Scala. First, you're going to need a couple of import statements:\n\n```scala\nimport org.apache.spark._\nimport org.apache.spark.graphx._\nimport org.apache.spark.graphx.lib._\n```\n\nNext, load the graph edges from the supplied `~/data/movie-edges.txt` file:\n\n```scala\nval graph = GraphLoader.edgeListFile(sc,\n    \"file:///home/vagrant/data/movie-edges.txt\")\n```\n\nThis file was generated from the same dataset, but it has a format that GraphX natively supports. You can check out the format by running the following commands:\n\n```\n$ head ~/data/movie-edges.txt\n0 1\n2 3\n2 4\n2 5\n2 6\n7 8\n9 10\n11 10\n12 10\n13 10\n$ head ~/data/movie-vertices.txt\n0 Howard Stern on Demand\n1 #1 Single\n2 #LawstinWoods\n3 Lost\n4 Kenny Rogers and Dolly Parton: Together\n5 The Grudge\n6 The Ring\n7 #MonologueWars\n8 Trainspotting\n9 Community\n```","dateUpdated":"Jun 22, 2016 9:12:42 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1466619042649_-363470692","id":"20160622-211042_1302082330","result":{"code":"SUCCESS","type":"HTML","msg":"<h4>Task 3: GraphX PageRank</h4>\n<p>The PageRank algorithm we implemented in the previous task is not very efficient. For example, running it on our dataset for 100 iterations took approximately 15 minutes on a 4-core machine. Considering that there are &ldquo;just&rdquo; about 25,000 movies ranked, this is not a very good result.</p>\n<p>Spark ships with a native graph algorithm library called GraphX. Unfortunately, it doesn't yet have a Python binding &ndash; you can only use it from Scala and Java. But we're not going to let that stop us!</p>\n<p>Navigate to the Spark installation directory (<code>~/spark</code> in the VirtualBox appliance) and run <code>bin/spark-shell</code>. This is the Spark Scala REPL, which is very similar to PySpark, except it uses Scala. First, you're going to need a couple of import statements:</p>\n<pre><code class=\"scala\">import org.apache.spark._\nimport org.apache.spark.graphx._\nimport org.apache.spark.graphx.lib._\n</code></pre>\n<p>Next, load the graph edges from the supplied <code>~/data/movie-edges.txt</code> file:</p>\n<pre><code class=\"scala\">val graph = GraphLoader.edgeListFile(sc,\n    \"file:///home/vagrant/data/movie-edges.txt\")\n</code></pre>\n<p>This file was generated from the same dataset, but it has a format that GraphX natively supports. You can check out the format by running the following commands:</p>\n<pre><code>$ head ~/data/movie-edges.txt\n0 1\n2 3\n2 4\n2 5\n2 6\n7 8\n9 10\n11 10\n12 10\n13 10\n$ head ~/data/movie-vertices.txt\n0 Howard Stern on Demand\n1 #1 Single\n2 #LawstinWoods\n3 Lost\n4 Kenny Rogers and Dolly Parton: Together\n5 The Grudge\n6 The Ring\n7 #MonologueWars\n8 Trainspotting\n9 Community\n</code></pre>\n"},"dateCreated":"Jun 22, 2016 9:10:42 PM","dateStarted":"Jun 22, 2016 9:11:55 PM","dateFinished":"Jun 22, 2016 9:11:55 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1070"},{"text":"%md\nThat's it -- we can run PageRank. Instead of working with a set number of iterations, the PageRank implementation in GraphX can run until the ranks converge (stop changing). We'll set the tolerance threshold to 0.0001, which means we're waiting for convergence up to that threshold. This computation took just under 2 minutes on the same machine!\n\n```scala\nval pageRank = PageRank.runUntilConvergence(graph, 0.0001).vertices.map(\n    p => (p._1.toInt, p._2)).cache()\n```\n\n> The resulting graph vertices are pairs of the vertex id and its rank. We use `toInt` to convert it to an int for the subsequent join operation.\n\nNext, load the vertices file that specifies the movie title for each id:\n\n```scala\nval titles = sc.textFile(\"file:///home/vagrant/data/movie-vertices.txt\").map(\n    line => {\n        val parts = line.split(\" \");\n        (parts(0).toInt, parts.drop(1).mkString(\" \"))\n    }\n)\n```\n\nFinally, join the ranks and the titles and sort the result to print the top 10 movies by rank:\n\n```scala\ntitles.join(pageRank).sortBy(-_._2._2).map(_._2).take(10)\n```\n","dateUpdated":"Jun 22, 2016 9:12:42 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1466619114986_-728289271","id":"20160622-211154_1136234575","result":{"code":"SUCCESS","type":"HTML","msg":"<p>That's it &ndash; we can run PageRank. Instead of working with a set number of iterations, the PageRank implementation in GraphX can run until the ranks converge (stop changing). We'll set the tolerance threshold to 0.0001, which means we're waiting for convergence up to that threshold. This computation took just under 2 minutes on the same machine!</p>\n<pre><code class=\"scala\">val pageRank = PageRank.runUntilConvergence(graph, 0.0001).vertices.map(\n    p =&gt; (p._1.toInt, p._2)).cache()\n</code></pre>\n<blockquote><p>The resulting graph vertices are pairs of the vertex id and its rank. We use <code>toInt</code> to convert it to an int for the subsequent join operation.</p>\n</blockquote>\n<p>Next, load the vertices file that specifies the movie title for each id:</p>\n<pre><code class=\"scala\">val titles = sc.textFile(\"file:///home/vagrant/data/movie-vertices.txt\").map(\n    line =&gt; {\n        val parts = line.split(\" \");\n        (parts(0).toInt, parts.drop(1).mkString(\" \"))\n    }\n)\n</code></pre>\n<p>Finally, join the ranks and the titles and sort the result to print the top 10 movies by rank:</p>\n<pre><code class=\"scala\">titles.join(pageRank).sortBy(-_._2._2).map(_._2).take(10)\n</code></pre>\n"},"dateCreated":"Jun 22, 2016 9:11:54 PM","dateStarted":"Jun 22, 2016 9:12:19 PM","dateFinished":"Jun 22, 2016 9:12:19 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1071"},{"text":"%md\n#### Discussion\n\nBesides being easier to use than implementing your own algorithms, why do you think GraphX has potential for being faster than something you'd roll by hand?\n","dateUpdated":"Jun 22, 2016 9:12:42 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1466619139625_837263871","id":"20160622-211219_1693153999","result":{"code":"SUCCESS","type":"HTML","msg":"<h4>Discussion</h4>\n<p>Besides being easier to use than implementing your own algorithms, why do you think GraphX has potential for being faster than something you'd roll by hand?</p>\n"},"dateCreated":"Jun 22, 2016 9:12:19 PM","dateStarted":"Jun 22, 2016 9:12:33 PM","dateFinished":"Jun 22, 2016 9:12:33 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1072"},{"dateUpdated":"Jun 22, 2016 9:12:42 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorHide":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1466619153276_-1486604162","id":"20160622-211233_630740313","dateCreated":"Jun 22, 2016 9:12:33 PM","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:1073"}],"name":"Lab 6 - Movie PageRank","id":"2BN9MADPU","angularObjects":{"2BPTZXB14":[],"2BMJRDTW3":[],"2BKPUUQTH":[],"2BKSECM3A":[],"2BN9ZJDBP":[],"2BKNGQUUG":[],"2BKAYKVR2":[],"2BKSAS565":[],"2BMPZT5XH":[],"2BNWNU8NC":[],"2BQ1AJWE4":[],"2BN44SKDU":[],"2BN59C6S8":[],"2BP824Q3U":[]},"config":{"looknfeel":"default"},"info":{}}